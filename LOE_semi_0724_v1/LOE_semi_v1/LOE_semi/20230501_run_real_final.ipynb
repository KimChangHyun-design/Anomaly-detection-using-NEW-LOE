{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d853bd-3da9-4718-bd1f-cfc18ddaa56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecd78b7-6fea-41e1-8af1-21199599808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.base import Grid, Config\n",
    "from evaluation.Experiments import runExperiment\n",
    "from evaluation.Kvariants_Eval import KVariantEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078fd6dc-d397-48ce-937c-7b211172c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please check below code in dataloader \n",
    "## Train_true_label is appelied for data training\n",
    "## It is different from run_real_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239cfa2-4ccd-45de-8236-94e2f9dd152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##In dataloder plz change the data input which will be used for training\n",
    "##The training outcome would not be saved the specific folder \n",
    "## You need to make a specific folder manually and individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2d284b-db9b-4cba-94da-eff3d90e8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lg_data_ntl_plus(contamination_rate,true_anomaly_rate):\n",
    "#     # 제품의 csv 파일 입력 부분\n",
    "#     #data = pd.read_csv(\"DATA/lg/CalibrationSample_M870AAA452.csv\",index_col=0) # done\n",
    "#     #data = pd.read_csv(\"DATA/lg/CalibrationSample_M871GBB551.csv\",index_col=0) # done--\n",
    "#     data = pd.read_csv(\"DATA/lg/CalibrationSample_M870AAA451.csv\",index_col=0) # done \n",
    "#     #data = pd.read_csv(\"DATA/lg/CalibrationSample_W822AAA152.csv\",index_col=0) # done\n",
    "#     #data = pd.read_csv(\"DATA/lg/CalibrationSample_M870AAA451.csv\",index_col=0)# done\n",
    "#     #data = pd.read_csv(\"DATA/lg/CalibrationSample_M872AAA031.csv\",index_col=0)# done-- \n",
    "    \n",
    "    \n",
    "#     data = data.reset_index()\n",
    "#     # 1. len_filter 적용\n",
    "#     # data_len = data[data['len_filter']==1].reset_index(drop=True)\n",
    "#     # 2. RESULT 적용\n",
    "#     #  data_len_ok = data_len[data_len['RESULT']=='OK']\n",
    "#     #  data_len_ok = data_len_ok.reset_index(drop=True) # reset index안해주면 len_barcode_seq가 안됨\n",
    "#     # 최종 사용할 data는 data_len_ok 임\n",
    "\n",
    "#     # LG 측에서 제공한 실제 고장 BARCODE_hash 입력\n",
    "#     #barcode_anomaly = ['gAAAAABhwo7BC3xrJ17V8mkX4-3sJ1S9xu0ltGqP8-ApcNxRD2hG8Hsc6Aa923ERs-sLsM4M2U68fZSkjTW5lTxWnhOiw3IdSwC-TkcbtKVveBNN6sUqL74='] # done\n",
    "#     #barcode_anomaly = ['gAAAAABhwo7CLznfZitvOF1Zt2S9DefyDvFi2hUbuYhtzKM-5yQcj-fsq-SK-s_9lF5VObM7hpSnkwmA20slXnCplQEfoDLX-wl9l0wkHCgZYXgGNr9ItfQ='] #done\n",
    "#     barcode_anomaly = ['gAAAAABhwo7C4eAPjtOdXWTW9tE84sjGYNtCGTEiK4gIaoSd_yU4ZPVSzL9B1nkHpSk0Mz1-6ONDExbPlqPRy3p6oimujuSGvYFYvv7KFNSAFe4NQDj8wVE='] # done\n",
    "#     #barcode_anomaly = ['gAAAAABib2XPayWAPUSOLHyWifIKhZHHszb4nNckJ86bAMLA3bpJzL-2JkwQrM_lsp-ic-UqC6GG2q1rh3m7ao4HwP2RnGtLaHZI79xRiJOoTee9EGsdEkM='] # done\n",
    "#     #barcode_anomaly = ['gAAAAABhwo7CJ2ay49VLou1_ff08fWfmjTJoU8OFB2yFvK-IWGSaqd5_Eu3i66AVsc3CKPlfKLr0lkJIaZEsj7t3FNDpZ3vq7q-3U8HqUFEwxCy1at-wl7c=']# done\n",
    "#     #barcode_anomaly = ['gAAAAABib2XRWkbhm2BsowH5oJK2rmYbsEiSsduDeaFqQlaFBDarSnzai2YoUN70EirGuxEDr0yNwN4gC7yUp8Nu3xLrWyIZ6glqSe_T4-CPaoKHHsnpVtc=']# done\n",
    "\n",
    "    \n",
    "    \n",
    "#     # 실제 고장 BARCODE_hash 입력받아 나오는 최종 고장 데이터 추출\n",
    "#     #(2598, 63)\n",
    "#     data_anomaly = data[data['BARCODE_hash'].isin(barcode_anomaly)]\n",
    "#     data_anomaly = data_anomaly.reset_index(drop=True)\n",
    "\n",
    "#     # 실제 고장 데이터 제외 정상 데이터\n",
    "#     #(4184079, 63)\n",
    "#     data_normal = data[~data['BARCODE_hash'].isin(barcode_anomaly)]\n",
    "#     data_normal = data_normal.reset_index(drop=True)\n",
    "\n",
    "#     # 정상 데이터와 실제 고장 데이터를 합쳐주는 과정\n",
    "#     ##(4186677, 63)\n",
    "#     final_samples = pd.concat([data_normal, data_anomaly], axis=0)\n",
    "#     final_samples=final_samples.reset_index(drop=True)\n",
    "\n",
    "#     # 정상 데이터와 실제 고장 데이터를 합친 전체 sample 개수 구함\n",
    "#     #(3223,)\n",
    "#     unique_ID = final_samples['BARCODE_SEQ'].unique()\n",
    "\n",
    "#     # 사용할 변수들 입력하는 과정(multivariate) , 추 후 더 입력이 가능함\n",
    "#     #output_features = ['F-DefrostSensorTemperature', 'R-DefrostSensorTemperature', 'Comp-Power', 'Comp-Phase', 'Comp-Current', 'Comp-Stroke']\n",
    "#     output_features = ['F-DefrostSensorTemperature', 'R-DefrostSensorTemperature', 'Comp-Power']\n",
    "#     #output_features = ['Comp-Power']\n",
    "\n",
    "#     # 딥러닝 모델을 적용하기 위해 final_samples에 스케일링 진행\n",
    "#     #(4186677, 6)\n",
    "#     scaler = StandardScaler()\n",
    "#     train_X_norm=scaler.fit_transform(final_samples.loc[:, output_features])\n",
    "#     # time-series 고려하기 위해 (sample갯수, sequence 길이, 변수 개수)로 변환\n",
    "#     #(3223, 1299, 6)\n",
    "#     x_train = train_X_norm.reshape(len(unique_ID), 1299, train_X_norm.shape[1])\n",
    "\n",
    "#     samples = x_train\n",
    "\n",
    "#     labels = np.zeros(samples.shape[0])\n",
    "#     # 고장 데이터 라벨 붙여주는 과정\n",
    "#     # 2 due to 2598/1299=2\n",
    "#     labels[samples.shape[0]-data_anomaly['BARCODE_SEQ'].unique().shape[0]:samples.shape[0]]=1\n",
    "\n",
    "#     # 최종적으로 전처리가 완료된 sample과 label \n",
    "\n",
    "#     samples = np.array(samples) \n",
    "#     labels = np.array(labels)\n",
    "\n",
    "#     inliers = samples[labels == 0]  # \n",
    "#     outliers = samples[labels == 1]  # 1 for anomalies\n",
    "\n",
    "#     num_split = len(inliers) // 2\n",
    "#     train_norm = inliers[:num_split]  # 1610,1299,6\n",
    "\n",
    "#     #inlier 데이터의 남은 반절과  outlier 데이터 셋을 결합\n",
    "#     test_data = np.concatenate([inliers[num_split:], outliers], 0)#1611+2\n",
    "#     test_label = np.zeros(test_data.shape[0])\n",
    "#     test_label[num_split:] = 1\n",
    "\n",
    "#     #train, train_label,train_true_label = synthetic_contamination_v2(train_norm, outliers, contamination_rate,true_anomaly_rate)\n",
    "#     train, train_label,train_true_label = synthetic_contamination_v2(train_norm, outliers, 0.1,true_anomaly_rate)\n",
    "\n",
    "#     train = np.transpose(train,(0,2,1))\n",
    "#     test_data = np.transpose(test_data,(0,2,1))\n",
    "\n",
    "#     return train, train_label, test_data, test_label,train_true_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16b3834-0e55-4ac0-be11-5708f876b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configurations = Grid('/media/usr/SSD/jitae/Thesis/Neural transformation/config_files/config_lg_ntl_plus_soft_v1.yml','lg_data_ntl_plus_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbf052f-9c3e-4037-8e3d-00692b198653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configuration = Config(**model_configurations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff66d4d-c957-4bc2-907f-628d1276d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list= [\"loe_soft\",\"loe_hard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a284e2-eeed-4137-9680-b7e54f1d2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_method_list = [\"loe_soft_semi\",\"loe_hard_semi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db59bb0b-5b41-4d51-9d81-ba88a15d3ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination_ratio = [0.15,0.1,0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8583f823-e362-402d-b6d7-ba524d93916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_anoamaly_ratio = [0.5,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2216bb3-c0ec-4220-bd17-ea2460daa20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_true_anoamaly_ratio = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a535bdb-f8d0-46b2-b6b1-9e722feb2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "items = [proposed_method_list, contamination_ratio,true_anoamaly_ratio]\n",
    "proposed_case=list(product(*items))\n",
    "items = [method_list, contamination_ratio,or_true_anoamaly_ratio]\n",
    "or_case=list(product(*items))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c199a19-f919-471b-ae24-1a35ad39b855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proposed_case),len(or_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf796de8-8e25-4c2b-83bb-1f5111d2a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_case=proposed_case + or_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e929ede-518e-4104-af82-aa36f9afb0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loe_soft_semi', 0.15, 0.5),\n",
       " ('loe_soft_semi', 0.15, 0.1),\n",
       " ('loe_soft_semi', 0.1, 0.5),\n",
       " ('loe_soft_semi', 0.1, 0.1),\n",
       " ('loe_soft_semi', 0.05, 0.5),\n",
       " ('loe_soft_semi', 0.05, 0.1),\n",
       " ('loe_hard_semi', 0.15, 0.5),\n",
       " ('loe_hard_semi', 0.15, 0.1),\n",
       " ('loe_hard_semi', 0.1, 0.5),\n",
       " ('loe_hard_semi', 0.1, 0.1),\n",
       " ('loe_hard_semi', 0.05, 0.5),\n",
       " ('loe_hard_semi', 0.05, 0.1),\n",
       " ('loe_soft', 0.15, 0),\n",
       " ('loe_soft', 0.1, 0),\n",
       " ('loe_soft', 0.05, 0),\n",
       " ('loe_hard', 0.15, 0),\n",
       " ('loe_hard', 0.1, 0),\n",
       " ('loe_hard', 0.05, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10c8652a-e5fc-436e-b6fd-ca00cb85911f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1_c_0.15_a_0.5_loe_soft_semi\n",
      "model1_c_0.15_a_0.1_loe_soft_semi\n",
      "model1_c_0.1_a_0.5_loe_soft_semi\n",
      "model1_c_0.1_a_0.1_loe_soft_semi\n",
      "model1_c_0.05_a_0.5_loe_soft_semi\n",
      "model1_c_0.05_a_0.1_loe_soft_semi\n"
     ]
    }
   ],
   "source": [
    "model_configurations = Grid('/media/usr/SSD/jitae/Thesis/Neural transformation/config_files/config_lg_ntl_plus_soft_v1.yml','lg_data_ntl_plus_v1')\n",
    "for i in range(6):\n",
    "#for i in range(1,2):    \n",
    "    simu_num= all_case[i][0]\n",
    "    #model_configuration.train_method = \n",
    "    #model_configuration.num_repeat='2'\n",
    "    model_configurations[0]['train_method'] =all_case[i][0]\n",
    "    model_configurations[0]['num_repeat'] =1\n",
    "    model_configuration = Config(**model_configurations[0])\n",
    "    #print(model_configuration.train_method)\n",
    "    #print(model_configurations[0]['train_method'])\n",
    "    \n",
    "    contamination=all_case[i][1]\n",
    "    anomaly_rate =all_case[i][2]\n",
    "    dataset =model_configuration.dataset\n",
    "    result_folder = model_configuration.result_folder+model_configuration.exp_name\n",
    "    exp_path = os.path.join(result_folder,f'model1_c_{contamination}_a_{anomaly_rate}_{model_configuration.train_method}')\n",
    "    print(f'model1_c_{contamination}_a_{anomaly_rate}_{model_configuration.train_method}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e30e33b3-52e2-458f-9e5b-2e7a34dc6411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Cls: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/usr/SSD/jitae/Thesis/Neural transformation/loader/LoadData.py:228: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"DATA/lg/CalibrationSample_M870AAA451.csv\",index_col=0) # done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, TR loss: 0.939164253130351, VAL loss: (0.9672931324351918, 0.9827774167060852), VL auc: 0.9393939393939394 VL ap: 0.1111111111111111 VL f1: 0.0 \n",
      "Epoch: 2, TR loss: 0.9361411316754067, VAL loss: (0.9064937360358961, 0.9213084578514099), VL auc: 0.75 VL ap: 0.029411764705882353 VL f1: 0.0 \n",
      "Epoch: 4, TR loss: 0.7260368556192477, VAL loss: (0.7638406464547822, 0.8513839840888977), VL auc: 0.9545454545454546 VL ap: 0.14285714285714285 VL f1: 0.0 \n",
      "Epoch: 6, TR loss: 0.5219919910169628, VAL loss: (0.5334560509883997, 0.930605411529541), VL auc: 1.0 VL ap: 1.0 VL f1: 1.0 \n",
      "Epoch: 8, TR loss: 0.3878366391952724, VAL loss: (0.42889895583644055, 1.0290136337280273), VL auc: 1.0 VL ap: 1.0 VL f1: 1.0 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m query_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m risk_assesser \u001b[38;5;241m=\u001b[39m KVariantEval(dataset, exp_path, model_configurations,contamination,query_num,anomaly_rate,simulation_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mrisk_assesser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrisk_assessment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunExperiment\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/usr/SSD/jitae/Thesis/Neural transformation/evaluation/Kvariants_Eval.py:136\u001b[0m, in \u001b[0;36mKVariantEval.risk_assessment\u001b[0;34m(self, experiment_class)\u001b[0m\n\u001b[1;32m    133\u001b[0m json_results \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_RESULTS_FILENAME)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(json_results):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_risk_assessment_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mexperiment_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already present! Shutting down to prevent loss of previous experiments\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/usr/SSD/jitae/Thesis/Neural transformation/evaluation/Kvariants_Eval.py:167\u001b[0m, in \u001b[0;36mKVariantEval._risk_assessment_helper\u001b[0;34m(self, cls, experiment_class, exp_path)\u001b[0m\n\u001b[1;32m    165\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m    166\u001b[0m trainset, valset, testset \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimu_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_name, \u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontamination, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_anomaly_rate)\n\u001b[0;32m--> 167\u001b[0m val_auc, test_auc, test_ap,test_f1, test_p_c, test_p_f, test_th, test_score \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtestset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontamination\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal training run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_auc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_auc,test_ap, test_f1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_p_c, test_p_f\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_th\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m val_auc_list\u001b[38;5;241m.\u001b[39mappend(val_auc)\n",
      "File \u001b[0;32m/media/usr/SSD/jitae/Thesis/Neural transformation/evaluation/Experiments.py:76\u001b[0m, in \u001b[0;36mrunExperiment.run_test\u001b[0;34m(self, train_data, val_data, test_data, logger, contamination, query_num)\u001b[0m\n\u001b[1;32m     69\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m trainer \u001b[38;5;241m=\u001b[39m trainer_class(model, loss_function\u001b[38;5;241m=\u001b[39mloss_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_temp\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     72\u001b[0m                  config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config)\n\u001b[1;32m     75\u001b[0m val_loss,val_auc,test_auc,test_ap,test_f1, test_p_c, test_p_f, test_th, test_score \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcontamination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontamination\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquery_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquery_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m              \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_auc, test_auc, test_ap,test_f1, test_p_c, test_p_f, test_th, test_score\n",
      "File \u001b[0;32m/media/usr/SSD/jitae/Thesis/Neural transformation/models/NeutralAD_trainer.py:212\u001b[0m, in \u001b[0;36mNeutralAD_trainer.train\u001b[0;34m(self, train_loader, contamination, query_num, optimizer, scheduler, validation_loader, test_loader, early_stopping, logger, log_every)\u001b[0m\n\u001b[1;32m    209\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     test_auc, test_ap, test_f1, test_p_c, test_p_f, test_th, test_score, testin_loss, testout_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     val_auc, val_ap,val_f1,  val_p_c, val_p_f, val_th, _, valin_loss,valout_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetect_outliers(validation_loader)\n",
      "File \u001b[0;32m/media/usr/SSD/jitae/Thesis/Neural transformation/models/NeutralAD_trainer.py:148\u001b[0m, in \u001b[0;36mNeutralAD_trainer.detect_outliers\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    146\u001b[0m labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# samples = samples.to(self.device)\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m z\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m loss_n,loss_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fun(z)\n\u001b[1;32m    150\u001b[0m score \u001b[38;5;241m=\u001b[39m loss_n\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsvdd/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/usr/SSD/jitae/Thesis/Neural transformation/models/NeutralAD.py:88\u001b[0m, in \u001b[0;36mSeqNeutralAD.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m xt \u001b[38;5;241m=\u001b[39m xt\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_trans\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     87\u001b[0m xt_np \u001b[38;5;241m=\u001b[39m xt\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 88\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnpy_xt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt_np\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m     90\u001b[0m zs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc[\u001b[38;5;241m0\u001b[39m](x_cat\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     91\u001b[0m zs \u001b[38;5;241m=\u001b[39m zs\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_trans\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_dim)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsvdd/lib/python3.10/site-packages/numpy/lib/npyio.py:522\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    521\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 522\u001b[0m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_imports\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsvdd/lib/python3.10/site-packages/numpy/lib/format.py:711\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 711\u001b[0m         \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[1;32m    714\u001b[0m                 array, flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternal_loop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    715\u001b[0m                 buffersize\u001b[38;5;241m=\u001b[39mbuffersize, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_configurations = Grid('/media/usr/SSD/jitae/Thesis/Neural transformation/config_files/config_lg_ntl_plus_soft_v1.yml','lg_data_ntl_plus_v1')\n",
    "#for i in range(len(all_case)):\n",
    "for i in range(1):\n",
    "#for i in range(1,2):    \n",
    "    model_configurations[0]['train_method'] =all_case[i][0]\n",
    "    model_configurations[0]['num_repeat'] =1\n",
    "    model_configuration = Config(**model_configurations[0])\n",
    "    model_configuration.train_method = all_case[i][0]\n",
    "    contamination=all_case[i][1]\n",
    "    anomaly_rate =all_case[i][2]\n",
    "    dataset =model_configuration.dataset\n",
    "    result_folder = model_configuration.result_folder+model_configuration.exp_name\n",
    "    exp_path = os.path.join(result_folder,f'c_{contamination}_a_{anomaly_rate}_{model_configuration.train_method}')\n",
    "    query_num = 0\n",
    "    risk_assesser = KVariantEval(dataset, exp_path, model_configurations,contamination,query_num,anomaly_rate,simulation_model=0)\n",
    "    risk_assesser.risk_assessment(runExperiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4dc73-df4c-4af0-8284-42272a50a6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff6ab9-460c-43a0-9d4a-35cd4087370c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsvdd",
   "language": "python",
   "name": "deepsvdd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
